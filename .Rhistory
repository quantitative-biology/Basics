dimnames(ctab)<-list("Actual"=c("absence(0)","presence(1)"), "Predicted"=c("absence(0)","presence(1)"))
ctab
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > 0.65, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
library(ROCit)
ROCit_obj <- rocit(score=glm.fit.sp$fitted.values,class=y)
pauc=plot(ROCit_obj)
summary(ROCit_obj)
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > round(max(ROCit_obj$TPR+(1-ROCit_obj$FPR)-1),2), 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
#simulate some temperature and occupancy data using a random number generator
xs=rnorm(200,  12,2.5)
ys=ifelse(xs>12, 1,0)
es=rnorm(200,0,.1)
#adding some randomness to simulated occupancy data
ys=ifelse(ys+es>=1., 1,0)
#create a dataframe with our temperature and occupancy data
ivsp=data.frame(temp=xs, occ=ys)
#randomly sample 75% of the data (by generating random numbers based on the number of rows)
samp=sample(nrow(ivsp), nrow(ivsp)*.75, replace = FALSE)
#divide into training and testing sets
train <- ivsp[samp, ]
test  <- ivsp[-samp, ]
#fit the logistic model on the training data
log.fit.inv=glm(occ~temp, family=binomial, data=train)
#test the logistic model on the testing data
log.predict <- predict(log.fit.inv,newdata=test,type = "response")
#determine predicted occupancy based on threshold value of 0.5
pred.occ <- ifelse(log.predict >0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(pred.occ, test$occ)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
#Calculate error rate, sensitivity and specificity
err=round((ctab[1,2]+ctab[2,1])/sum(ctab),2)
sens=round(ctab[2,2]/(ctab[2,1]+ctab[2,2]),2)
spec=round(1-ctab[1,2]/(ctab[1,1]+ctab[1,2]),2)
print(paste0("error rate=",err, "; sensitivity=", sens, "; specificity=", spec))
library(caret)
#cross-validation with 5 folds
train_control <- trainControl(method = "cv", number = 5)
#fit the logistic regression
hab <- train(as.factor(occ) ~ temp, data = train,
trControl = train_control,
method = "glm",
family = "binomial")
confusionMatrix(hab)
summary(hab$finalModel)
habprob<-hab$finalModel$fitted.values
#t is the threshold for which the confusion matrix shall be computed
habclass <- function(t) ifelse(habprob > t , 1,0)
#test with confusion matrix
confusionMatrix(as.factor(habclass(0.5)),as.factor((train$occ)))
x2=ifelse(y==1, "urban", "rural")
e2=rnorm(200,0,.1)
x2=ifelse(y+e2<1., "rural",x2 )
x2=ifelse(e2>0.1, "urban", x2)
glm.fit.sp2=glm(y~x+as.factor(x2), family=binomial)
logcoefs2=round(as.data.frame(summary(glm.fit.sp2)$coefficients),2)
knitr::kable(logcoefs2, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data with temperature and land category as predictors")
plot(y~x, col=as.factor(x2),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
legend("topleft", c("urban", "rural"), pch=1, col=c(2, "black"), bty="n")
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x)/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x)), add=TRUE, col="black", lwd=2)
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])), add=TRUE, col=2, lwd=2)
library(MASS)
data("iris")
train <- sample(1:150, 75)
irislda <- lda(Species ~ ., iris, subset = train)
irislda
plda = predict(irislda, newdata = iris[-train, ])
confusionMatrix(iris$Species[-train], plda$class)
plot(plda$x, col=plda$class, pch=as.numeric(iris[-train,"Species"])+14, ylim=c(-4,4))
legend("bottom", legend=unique(iris[-train,"Species"]),
pch=as.numeric(unique(iris[-train,"Species"]))+14, col=1:3, bty="n")
ldahist(plda$x[,1], g=plda$'class', col=2, cex=1.5, cex.lab=1.75,
xlim=c(-15,10), ymax=0.5)
library(rpart)
alpha     <- 0.7 # percentage of training set
inTrain   <- sample(1:nrow(iris), alpha * nrow(iris))
train.set <- iris[inTrain,]
test.set  <- iris[-inTrain,]
mytree <- rpart(Species ~ ., data = train.set, method = "class")
par(mar=c(5,3,3,3))
plot(mytree)
text(mytree, cex=1.2)
library(rpart)
alpha     <- 0.7 # percentage of training set
inTrain   <- sample(1:nrow(iris), alpha * nrow(iris))
train.set <- iris[inTrain,]
test.set  <- iris[-inTrain,]
mytree <- rpart(Species ~ ., data = train.set, method = "class")
par(mar=c(5,3,3,3))
plot(mytree)
text(mytree, cex=1.2)
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE,kableExtra.auto_format = FALSE)
library(kableExtra)
#create some synthetic data with random variation
x=rnorm(200,  12,2.5)
y=x
y=ifelse(x>12, 1,0)
e=rnorm(200,0,.1)
y=ifelse(y+e>=1., 1,0)
#plot the data and the regression line
plot(y~x,pch=16,ylim=c(-0.1,1.1),
xlim=c(0, 20),col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
lreg=lm(y~x)
abline(lreg, col=2, lwd=2)
glm.fit.sp=glm(y~x, family=binomial)
glm.probs <- predict(glm.fit.sp,type = "response")
#plot the data
plot(y~x,pch=16,ylim=c(-0.1,1.1), col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
#save the regression coefficients
logcoefs=round(as.data.frame(summary(glm.fit.sp)$coefficients),2)
#plot the fitted curve using the saved coefficients
curve(exp(logcoefs[1,1]+logcoefs[2,1]*x)/(1+exp(logcoefs[1,1]+logcoefs[2,1]*x)), add=TRUE, col=2, lwd=2)
knitr::kable(logcoefs, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data")
#determine model occurrence predictions based on threshold value
logocc <- ifelse(glm.probs > 0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c("absence(0)","presence(1)"), "Predicted"=c("absence(0)","presence(1)"))
ctab
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > 0.65, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
library(ROCit)
ROCit_obj <- rocit(score=glm.fit.sp$fitted.values,class=y)
pauc=plot(ROCit_obj)
summary(ROCit_obj)
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > round(max(ROCit_obj$TPR+(1-ROCit_obj$FPR)-1),2), 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
#simulate some temperature and occupancy data using a random number generator
xs=rnorm(200,  12,2.5)
ys=ifelse(xs>12, 1,0)
es=rnorm(200,0,.1)
#adding some randomness to simulated occupancy data
ys=ifelse(ys+es>=1., 1,0)
#create a dataframe with our temperature and occupancy data
ivsp=data.frame(temp=xs, occ=ys)
#randomly sample 75% of the data (by generating random numbers based on the number of rows)
samp=sample(nrow(ivsp), nrow(ivsp)*.75, replace = FALSE)
#divide into training and testing sets
train <- ivsp[samp, ]
test  <- ivsp[-samp, ]
#fit the logistic model on the training data
log.fit.inv=glm(occ~temp, family=binomial, data=train)
#test the logistic model on the testing data
log.predict <- predict(log.fit.inv,newdata=test,type = "response")
#determine predicted occupancy based on threshold value of 0.5
pred.occ <- ifelse(log.predict >0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(pred.occ, test$occ)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
#Calculate error rate, sensitivity and specificity
err=round((ctab[1,2]+ctab[2,1])/sum(ctab),2)
sens=round(ctab[2,2]/(ctab[2,1]+ctab[2,2]),2)
spec=round(1-ctab[1,2]/(ctab[1,1]+ctab[1,2]),2)
print(paste0("error rate=",err, "; sensitivity=", sens, "; specificity=", spec))
library(caret)
#cross-validation with 5 folds
train_control <- trainControl(method = "cv", number = 5)
#fit the logistic regression
hab <- train(as.factor(occ) ~ temp, data = train,
trControl = train_control,
method = "glm",
family = "binomial")
confusionMatrix(hab)
summary(hab$finalModel)
habprob<-hab$finalModel$fitted.values
#t is the threshold for which the confusion matrix shall be computed
habclass <- function(t) ifelse(habprob > t , 1,0)
#test with confusion matrix
confusionMatrix(as.factor(habclass(0.5)),as.factor((train$occ)))
x2=ifelse(y==1, "urban", "rural")
e2=rnorm(200,0,.1)
x2=ifelse(y+e2<1., "rural",x2 )
x2=ifelse(e2>0.1, "urban", x2)
glm.fit.sp2=glm(y~x+as.factor(x2), family=binomial)
logcoefs2=round(as.data.frame(summary(glm.fit.sp2)$coefficients),2)
knitr::kable(logcoefs2, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data with temperature and land category as predictors")
plot(y~x, col=as.factor(x2),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
legend("topleft", c("urban", "rural"), pch=1, col=c(2, "black"), bty="n")
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x)/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x)), add=TRUE, col="black", lwd=2)
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])), add=TRUE, col=2, lwd=2)
library(MASS)
data("iris")
train <- sample(1:150, 75)
irislda <- lda(Species ~ ., iris, subset = train)
irislda
plda = predict(irislda, newdata = iris[-train, ])
confusionMatrix(iris$Species[-train], plda$class)
plot(plda$x, col=plda$class, pch=as.numeric(iris[-train,"Species"])+14, ylim=c(-4,4))
legend("bottom", legend=unique(iris[-train,"Species"]),
pch=as.numeric(unique(iris[-train,"Species"]))+14, col=1:3, bty="n")
ldahist(plda$x[,1], g=plda$'class', col=2, cex=1.5, cex.lab=1.75,
xlim=c(-15,10), ymax=0.5)
library(rpart)
alpha     <- 0.7 # percentage of training set
inTrain   <- sample(1:nrow(iris), alpha * nrow(iris))
train.set <- iris[inTrain,]
test.set  <- iris[-inTrain,]
mytree <- rpart(Species ~ ., data = train.set, method = "class")
par(mar=c(5,3,3,3))
plot(mytree)
text(mytree, cex=1.2)
library(rpart.plot)
rpart.plot(mytree, box.palette=0)
pred <- predict(mytree, test.set, type="class")
confusionMatrix(pred, test.set$Species)
library(randomForest)
RF.model = randomForest(Species ~ ., data = iris)
RF.model
plot(RF.model, main="", cex=1.5, lwd=2, cex.lab=2)
legend("topright", c("OOB", "setosa", "versicolor", "virginica"), col=c(1,2,3,4), lty=c(1,2,3,4), bty="n",  lwd=2)
plot(RF.model, main="", cex=1.5, lwd=2, cex.lab=1.5)
legend("topright", c("OOB", "setosa", "versicolor", "virginica"), col=c(1,2,3,4), lty=c(1,2,3,4), bty="n",  lwd=2)
varImpPlot(RF.model, cex=1.3, pch=16)
partialPlot(RF.model, iris, Petal.Length, main="", ylab="log odds", cex=1.3, lwd=2,cex.lab=1.3)
partialPlot(RF.model, iris, Petal.Length, main="", ylab="log odds", cex=1.3, lwd=2,cex.lab=1.3)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE,kableExtra.auto_format = FALSE)
library(kableExtra)
#create some synthetic data with random variation
x=rnorm(200,  12,2.5)
y=x
y=ifelse(x>12, 1,0)
e=rnorm(200,0,.1)
y=ifelse(y+e>=1., 1,0)
#plot the data and the regression line
plot(y~x,pch=16,ylim=c(-0.1,1.1),
xlim=c(0, 20),col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
lreg=lm(y~x)
abline(lreg, col=2, lwd=2)
glm.fit.sp=glm(y~x, family=binomial)
glm.probs <- predict(glm.fit.sp,type = "response")
#plot the data
plot(y~x,pch=16,ylim=c(-0.1,1.1), col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
#save the regression coefficients
logcoefs=round(as.data.frame(summary(glm.fit.sp)$coefficients),2)
#plot the fitted curve using the saved coefficients
curve(exp(logcoefs[1,1]+logcoefs[2,1]*x)/(1+exp(logcoefs[1,1]+logcoefs[2,1]*x)), add=TRUE, col=2, lwd=2)
knitr::kable(logcoefs, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data")
#determine model occurrence predictions based on threshold value
logocc <- ifelse(glm.probs > 0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c("absence(0)","presence(1)"), "Predicted"=c("absence(0)","presence(1)"))
ctab
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > 0.65, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
library(ROCit)
ROCit_obj <- rocit(score=glm.fit.sp$fitted.values,class=y)
pauc=plot(ROCit_obj)
summary(ROCit_obj)
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > round(max(ROCit_obj$TPR+(1-ROCit_obj$FPR)-1),2), 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
#simulate some temperature and occupancy data using a random number generator
xs=rnorm(200,  12,2.5)
ys=ifelse(xs>12, 1,0)
es=rnorm(200,0,.1)
#adding some randomness to simulated occupancy data
ys=ifelse(ys+es>=1., 1,0)
#create a dataframe with our temperature and occupancy data
ivsp=data.frame(temp=xs, occ=ys)
#randomly sample 75% of the data (by generating random numbers based on the number of rows)
samp=sample(nrow(ivsp), nrow(ivsp)*.75, replace = FALSE)
#divide into training and testing sets
train <- ivsp[samp, ]
test  <- ivsp[-samp, ]
#fit the logistic model on the training data
log.fit.inv=glm(occ~temp, family=binomial, data=train)
#test the logistic model on the testing data
log.predict <- predict(log.fit.inv,newdata=test,type = "response")
#determine predicted occupancy based on threshold value of 0.5
pred.occ <- ifelse(log.predict >0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(pred.occ, test$occ)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
#Calculate error rate, sensitivity and specificity
err=round((ctab[1,2]+ctab[2,1])/sum(ctab),2)
sens=round(ctab[2,2]/(ctab[2,1]+ctab[2,2]),2)
spec=round(1-ctab[1,2]/(ctab[1,1]+ctab[1,2]),2)
print(paste0("error rate=",err, "; sensitivity=", sens, "; specificity=", spec))
library(caret)
#cross-validation with 5 folds
train_control <- trainControl(method = "cv", number = 5)
#fit the logistic regression
hab <- train(as.factor(occ) ~ temp, data = train,
trControl = train_control,
method = "glm",
family = "binomial")
confusionMatrix(hab)
summary(hab$finalModel)
habprob<-hab$finalModel$fitted.values
#t is the threshold for which the confusion matrix shall be computed
habclass <- function(t) ifelse(habprob > t , 1,0)
#test with confusion matrix
confusionMatrix(as.factor(habclass(0.5)),as.factor((train$occ)))
x2=ifelse(y==1, "urban", "rural")
e2=rnorm(200,0,.1)
x2=ifelse(y+e2<1., "rural",x2 )
x2=ifelse(e2>0.1, "urban", x2)
glm.fit.sp2=glm(y~x+as.factor(x2), family=binomial)
logcoefs2=round(as.data.frame(summary(glm.fit.sp2)$coefficients),2)
knitr::kable(logcoefs2, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data with temperature and land category as predictors")
plot(y~x, col=as.factor(x2),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
legend("topleft", c("urban", "rural"), pch=1, col=c(2, "black"), bty="n")
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x)/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x)), add=TRUE, col="black", lwd=2)
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])), add=TRUE, col=2, lwd=2)
library(MASS)
data("iris")
train <- sample(1:150, 75)
irislda <- lda(Species ~ ., iris, subset = train)
irislda
plda = predict(irislda, newdata = iris[-train, ])
confusionMatrix(iris$Species[-train], plda$class)
plot(plda$x, col=plda$class+1, pch=as.numeric(plda$class)+14, ylim=c(-4,4))
legend("bottom", levels(iris[-train,"Species"]),bty="n",
pch=as.numeric(unique(plda$class))+14,
col=as.numeric(unique(plda$class))+1)
str(plda)
str(plda$class)
as.numeric(plda$class)+14
plda$class+1
plot(plda$x, col=as.numeric(plda$class)+1, pch=as.numeric(plda$class)+14, ylim=c(-4,4))
legend("bottom", levels(iris[-train,"Species"]),bty="n",
pch=as.numeric(unique(plda$class))+14,
col=as.numeric(unique(plda$class))+1)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
rm(list=ls())
knitr::opts_chunk$set(echo = FALSE,kableExtra.auto_format = FALSE)
library(kableExtra)
#create some synthetic data with random variation
x=rnorm(200,  12,2.5)
y=x
y=ifelse(x>12, 1,0)
e=rnorm(200,0,.1)
y=ifelse(y+e>=1., 1,0)
#plot the data and the regression line
plot(y~x,pch=16,ylim=c(-0.1,1.1),
xlim=c(0, 20),col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
lreg=lm(y~x)
abline(lreg, col=2, lwd=2)
glm.fit.sp=glm(y~x, family=binomial)
glm.probs <- predict(glm.fit.sp,type = "response")
#plot the data
plot(y~x,pch=16,ylim=c(-0.1,1.1), col=rgb(0.1, 0.3, 0.4, 0.6),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
#save the regression coefficients
logcoefs=round(as.data.frame(summary(glm.fit.sp)$coefficients),2)
#plot the fitted curve using the saved coefficients
curve(exp(logcoefs[1,1]+logcoefs[2,1]*x)/(1+exp(logcoefs[1,1]+logcoefs[2,1]*x)), add=TRUE, col=2, lwd=2)
knitr::kable(logcoefs, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data")
#determine model occurrence predictions based on threshold value
logocc <- ifelse(glm.probs > 0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c("absence(0)","presence(1)"), "Predicted"=c("absence(0)","presence(1)"))
ctab
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > 0.65, 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
library(ROCit)
ROCit_obj <- rocit(score=glm.fit.sp$fitted.values,class=y)
pauc=plot(ROCit_obj)
summary(ROCit_obj)
#determine model predictions based on threshold value
logocc <- ifelse(glm.probs > round(max(ROCit_obj$TPR+(1-ROCit_obj$FPR)-1),2), 1, 0)
#Calculate a confusion matrix
ctab=table(logocc, y)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
err=(ctab[1,2]+ctab[2,1])/sum(ctab)
sens=ctab[2,2]/(ctab[2,1]+ctab[2,2])
spec=1-ctab[1,2]/(ctab[1,1]+ctab[1,2])
#simulate some temperature and occupancy data using a random number generator
xs=rnorm(200,  12,2.5)
ys=ifelse(xs>12, 1,0)
es=rnorm(200,0,.1)
#adding some randomness to simulated occupancy data
ys=ifelse(ys+es>=1., 1,0)
#create a dataframe with our temperature and occupancy data
ivsp=data.frame(temp=xs, occ=ys)
#randomly sample 75% of the data (by generating random numbers based on the number of rows)
samp=sample(nrow(ivsp), nrow(ivsp)*.75, replace = FALSE)
#divide into training and testing sets
train <- ivsp[samp, ]
test  <- ivsp[-samp, ]
#fit the logistic model on the training data
log.fit.inv=glm(occ~temp, family=binomial, data=train)
#test the logistic model on the testing data
log.predict <- predict(log.fit.inv,newdata=test,type = "response")
#determine predicted occupancy based on threshold value of 0.5
pred.occ <- ifelse(log.predict >0.5, 1, 0)
#Calculate a confusion matrix
ctab=table(pred.occ, test$occ)
dimnames(ctab)<-list("Actual"=c(0.,1), "Predicted"=c(0,1))
ctab
#Calculate error rate, sensitivity and specificity
err=round((ctab[1,2]+ctab[2,1])/sum(ctab),2)
sens=round(ctab[2,2]/(ctab[2,1]+ctab[2,2]),2)
spec=round(1-ctab[1,2]/(ctab[1,1]+ctab[1,2]),2)
print(paste0("error rate=",err, "; sensitivity=", sens, "; specificity=", spec))
library(caret)
#cross-validation with 5 folds
train_control <- trainControl(method = "cv", number = 5)
#fit the logistic regression
hab <- train(as.factor(occ) ~ temp, data = train,
trControl = train_control,
method = "glm",
family = "binomial")
confusionMatrix(hab)
summary(hab$finalModel)
habprob<-hab$finalModel$fitted.values
#t is the threshold for which the confusion matrix shall be computed
habclass <- function(t) ifelse(habprob > t , 1,0)
#test with confusion matrix
confusionMatrix(as.factor(habclass(0.5)),as.factor((train$occ)))
x2=ifelse(y==1, "urban", "rural")
e2=rnorm(200,0,.1)
x2=ifelse(y+e2<1., "rural",x2 )
x2=ifelse(e2>0.1, "urban", x2)
glm.fit.sp2=glm(y~x+as.factor(x2), family=binomial)
logcoefs2=round(as.data.frame(summary(glm.fit.sp2)$coefficients),2)
knitr::kable(logcoefs2, digits=2, caption="Logistic regression coefficient estimates and hypothesis tests from species occurrence data with temperature and land category as predictors")
plot(y~x, col=as.factor(x2),ylab="Species occurrence", xlab="Mean annual temperature (°C)", cex.lab=1.5, las=1)
legend("topleft", c("urban", "rural"), pch=1, col=c(2, "black"), bty="n")
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x)/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x)), add=TRUE, col="black", lwd=2)
curve(exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])/(1+exp(logcoefs2[1,1]+logcoefs2[2,1]*x+logcoefs2[3,1])), add=TRUE, col=2, lwd=2)
library(MASS)
data("iris")
train <- sample(1:150, 75)
irislda <- lda(Species ~ ., iris, subset = train)
irislda
plda = predict(irislda, newdata = iris[-train, ])
confusionMatrix(iris$Species[-train], plda$class)
plot(plda$x, col=as.numeric(plda$class)+1, pch=as.numeric(plda$class)+14, ylim=c(-4,4))
legend("bottom", levels(iris[-train,"Species"]),bty="n",
pch=as.numeric(unique(plda$class))+14,
col=as.numeric(unique(plda$class))+1)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
x =0
y =0
plot(x,y, type = "n", xlim = c(-100,100), ylim = c(-100,100), frame.plot = FALSE, xaxt = "n", yaxt= "n", ann = FALSE)
par(mar = c(5,7,5,4))
abline(h=0, v=0)
text(x=-50, y=50, labels = "Regression", col = 1, cex = 1.3)
text(x=50, y=50, labels = "Classification", col = 2, cex = 1.3)
text(x=-50, y=-50, labels = "Ordination", col = 3, cex = 1.3)
text(x=50, y=-50, labels = "Clustering", col = 4, cex = 1.3)
#title(main = "Types of Multivariate Analysis")
mtext("Discrete", side = 4, line = 0.3, at=0, las = 1)
mtext("Latent Variable", side = 1, line = 0.3, at = 0)
mtext("Continuous", side = 2, line = 0.3, at = 0, las = 1)
mtext("Response Variable", side = 3, line = 0.3, at = 0)
